{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d8fefa2-cfc2-4a6d-8bdc-23661fd2ee4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log and Register the ProteinMPNN model to Unity Catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8de7f4c7-778a-4b7f-ac2d-825721c88e69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install ../proteinmpnn\n",
    "# some extras we specify with pip requirements file to handle the extra url paths needed for odd cuda specific versions of packages\n",
    "%pip install -r ../envs/requirements.txt\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73a7b1be-0386-4c62-97ac-e973686bd21f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from proteinmpnn.run import main, get_argparser\n",
    "from proteinmpnn.parse_multiple_chains import main as pdb_main\n",
    "from proteinmpnn.parse_multiple_chains import get_argparser as pdb_get_argparser\n",
    "import tempfile\n",
    "\n",
    "from typing import Optional,List\n",
    "\n",
    "import mlflow\n",
    "from mlflow.types.schema import ColSpec, Schema\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2b53865-6852-4efa-9dd4-10a3a1cf3a87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define our model as a subclass of mlflow's PythonModel \n",
    " - internally has a pointer to the model weights (stored as artifact with the model)\n",
    " - runs the main proteinmpnn inference command on predict, after preparing the input to correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29dbe957-a1db-45a2-982b-34c64b2e452d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ProteinMPNN(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.model_dir = context.artifacts['model_dir']\n",
    "\n",
    "    def _prepare_pdb_input(self,pdb_str:str,outdir:str):\n",
    "        \n",
    "        from proteinmpnn.parse_multiple_chains import main as pdb_main\n",
    "        from proteinmpnn.parse_multiple_chains import get_argparser as pdb_get_argparser\n",
    "        import tempfile\n",
    "        parser = pdb_get_argparser()\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            with open(temp_dir + \"/my_pdb.pdb\", \"w\") as f:\n",
    "                f.write(pdb_str)\n",
    "            \n",
    "            arg_list = []\n",
    "            # arg_list.extend(['--ca_only'])\n",
    "            arg_list.extend(['--input_path', temp_dir])\n",
    "            arg_list.extend(['--output_path', f'{outdir}/inputs.jsonl'])\n",
    "            args = parser.parse_args(arg_list)\n",
    "            pdb_main(args)\n",
    "        return None\n",
    "\n",
    "    def _run_proteinmpnn(self,input_path, output_dir):\n",
    "        from proteinmpnn.run import main, get_argparser\n",
    "\n",
    "        parser = get_argparser()\n",
    "        arg_list = []\n",
    "        arg_list.extend(['--suppress_print', \"1\"])\n",
    "        # arg_list.extend(['--ca_only'])\n",
    "        arg_list.extend(['--jsonl_path', input_path])\n",
    "        arg_list.extend(['--out_folder', output_dir])\n",
    "        arg_list.extend(['--num_seq_per_target', \"3\"])\n",
    "        arg_list.extend(['--sampling_temp', \"0.1\"])\n",
    "        arg_list.extend(['--batch_size', \"1\"])\n",
    "        arg_list.extend(['--path_to_model_weights', self.model_dir])\n",
    "        args = parser.parse_args(arg_list)\n",
    "\n",
    "        main(args)\n",
    "        return None\n",
    "\n",
    "\n",
    "    def predict(self, context, inputs : List[str], params=None) -> List[str]:\n",
    "        \"\"\"\n",
    "        parameters: \n",
    "        -----------\n",
    "        inputs: single entry list (currently) of pdb string for a PDB with only backbone atoms\n",
    "        \"\"\"\n",
    "        import tempfile\n",
    "        if len(inputs)!= 1:\n",
    "            raise ValueError(\"Expected exactly one input\")\n",
    "        pdb_str= inputs[0]\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            self._prepare_pdb_input(pdb_str,tmpdir)\n",
    "            with tempfile.TemporaryDirectory() as outdir:\n",
    "                self._run_proteinmpnn(tmpdir+'/inputs.jsonl', outdir)\n",
    "                with open(outdir+'/seqs/my_pdb.fa', 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                seqs = lines[3::2]\n",
    "        return [s.strip() for s in seqs]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee6e11a6-bee1-4e07-b13b-55cf87a940b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test running the model with the test input we prepared in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b49e76c-17a8-447b-ad6a-d72abfb5510b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = ProteinMPNN()\n",
    "\n",
    "artifacts={\n",
    "    \"model_dir\" : \"/Volumes/protein_folding/proteinmpnn/model_weights/vanilla_model_weights/\",\n",
    "}\n",
    "context=mlflow.pyfunc.PythonModelContext(artifacts=artifacts, model_config=dict())\n",
    "model.load_context(context)\n",
    "\n",
    "with open('../example_data/inputs/5yd3.pdb', 'r') as f:\n",
    "    in_pdb_str = f.read()\n",
    "\n",
    "seqs = model.predict(\n",
    "    context,\n",
    "    [in_pdb_str]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e79ef72-45ac-4502-ac21-870861194b2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e7ecfce-137f-4f41-9e00-ff125b186a05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## register our model to Unity Catalog\n",
    " - first we make a copy of the proteinmpnn repo to the compute's local disk and then add it to the model so that the source code is stored along with the model\n",
    " - this allows us to use a path to that artifact in the conda environment we specify with the model so that we can pip install the package along with the model (even though the package is not on pypi and is locally defined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16273471-ed37-4df0-a619-1eb66a966e4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "# move a copy of our code base to \"local\" machine and then register it with the model\n",
    "# this will make a copy of our codebase that we can then install on the server for model serving\n",
    "mkdir -p /local_disk0/proteinmpnn\n",
    "cp -r ../proteinmpnn/src /local_disk0/proteinmpnn\n",
    "cp ../proteinmpnn/pyproject.toml /local_disk0/proteinmpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b244a64a-a49b-4a6f-a97e-b50b79312018",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "ls /local_disk0/proteinmpnn\n",
    "ls /local_disk0/proteinmpnn/src/proteinmpnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "620630d4-dc7e-4220-8e73-aad5f36edd40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "signature = mlflow.models.signature.ModelSignature(\n",
    "    inputs = Schema([ColSpec(type=\"string\")]),\n",
    "    outputs = Schema([ColSpec(type=\"string\")]),\n",
    "    params = None\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name='protein_mpnn'):\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=ProteinMPNN(),\n",
    "        artifacts={\n",
    "            \"model_dir\" : \"/Volumes/protein_folding/proteinmpnn/model_weights/vanilla_model_weights/\",\n",
    "            'repo_path': '/local_disk0/proteinmpnn'\n",
    "        },\n",
    "        input_example=[in_pdb_str],\n",
    "        signature=signature,\n",
    "        conda_env='../envs/conda_env.yaml',\n",
    "        registered_model_name=\"protein_folding.proteinmpnn.proteinmpnn\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "618f8696-1e9d-4bcd-8451-ad26116975c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8187281512173635,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_log_proteinmpnn",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
